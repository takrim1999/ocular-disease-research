{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries for ResNet synthetic data classification\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Try to import tensorflow_addons, if not available, define alternative metrics\n",
        "try:\n",
        "    import tensorflow_addons as tfa\n",
        "    from tensorflow_addons.metrics import F1Score\n",
        "    HAS_TFA = True\n",
        "    custom_objects = {'F1Score': F1Score}\n",
        "    print(\"Using tensorflow_addons\")\n",
        "except ImportError:\n",
        "    print(\"Warning: tensorflow_addons not available. Using alternative F1 score implementation.\")\n",
        "    HAS_TFA = False\n",
        "    \n",
        "    # Define a simple F1 score metric as alternative\n",
        "    class F1Score(tf.keras.metrics.Metric):\n",
        "        def __init__(self, num_classes, average='weighted', name='f1', **kwargs):\n",
        "            super(F1Score, self).__init__(name=name, **kwargs)\n",
        "            self.num_classes = num_classes\n",
        "            self.average = average\n",
        "            self.precision = tf.keras.metrics.Precision()\n",
        "            self.recall = tf.keras.metrics.Recall()\n",
        "            \n",
        "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "            y_pred = tf.argmax(y_pred, axis=1)\n",
        "            y_true = tf.argmax(y_true, axis=1)\n",
        "            self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "            self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "            \n",
        "        def result(self):\n",
        "            p = self.precision.result()\n",
        "            r = self.recall.result()\n",
        "            return 2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n",
        "            \n",
        "        def reset_state(self):\n",
        "            self.precision.reset_state()\n",
        "            self.recall.reset_state()\n",
        "    \n",
        "    custom_objects = {'F1Score': F1Score}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet50 Synthetic Data Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the desired image size for model input\n",
        "image_size = (224, 224)\n",
        "\n",
        "# Define the class labels\n",
        "class_labels = ['glaucoma', 'cataract', 'hyper', 'myopia', 'amd']\n",
        "\n",
        "# Set the directory where the test images are stored\n",
        "test_data_dir = '/content/gdrive/MyDrive/Ocular_Disease/sd_outputs'\n",
        "\n",
        "# Create directories for storing images by their predicted class labels\n",
        "for label in class_labels:\n",
        "    label_dir = os.path.join(test_data_dir, 'resnet_results', label)\n",
        "    tf.io.gfile.makedirs(label_dir)  # Ensure the directory exists for each label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved ResNet model (replace with your actual model path)\n",
        "try:\n",
        "    with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "        model = load_model('./resnet_ocular_disease_model.h5')\n",
        "    print(\"ResNet model loaded successfully!\")\n",
        "except:\n",
        "    print(\"Model file not found. Creating a new ResNet50 model...\")\n",
        "    \n",
        "    # Create a new ResNet50 model if the saved model is not available\n",
        "    resnet = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "    \n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = True\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(resnet)\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(512, activation=\"relu\"))\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dense(5, activation=\"softmax\"))\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\n",
        "            tf.keras.metrics.CategoricalAccuracy(name=\"acc\"),\n",
        "            tfa.metrics.F1Score(num_classes=5, average=\"weighted\", name=\"f1\"),\n",
        "            tf.keras.metrics.AUC(name=\"auc\"),\n",
        "        ]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification of Synthetic Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterate over each class folder\n",
        "for class_label in class_labels:\n",
        "    # Get all images from the class directory\n",
        "    class_dir = os.path.join(test_data_dir, class_label)\n",
        "    test_images = os.listdir(class_dir)  # Get all image filenames from the current class folder\n",
        "\n",
        "    print(f\"Processing {class_label} images...\")\n",
        "    \n",
        "    # Process each test image, make predictions, and save them in the corresponding directory\n",
        "    for image_file in test_images:\n",
        "        # Load and preprocess the image\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = load_img(image_path, target_size=image_size)  # Resize image\n",
        "        image_array = img_to_array(image)  # Convert image to an array\n",
        "        image_tensor = tf.expand_dims(image_array, 0)  # Add batch dimension\n",
        "\n",
        "        # Get model's prediction for the image\n",
        "        outputs = model.predict(image_tensor)\n",
        "        predicted = tf.argmax(outputs, axis=1)  # Get index of predicted class\n",
        "        predicted_label = class_labels[predicted.numpy()[0]]  # Get the label name based on prediction\n",
        "\n",
        "        # Print the prediction result for reference (only for first few images to avoid spam)\n",
        "        if len(test_images) <= 10 or test_images.index(image_file) < 5:\n",
        "            print(f'Image: {image_file}, Predicted class: {predicted_label}')\n",
        "\n",
        "        # Move the image to the corresponding folder for its predicted class\n",
        "        destination_dir = os.path.join(test_data_dir, 'resnet_results', predicted_label)\n",
        "        destination_path = os.path.join(destination_dir, image_file)  # Define the path to save the image\n",
        "        shutil.copyfile(image_path, destination_path)  # Copy image to the appropriate folder\n",
        "\n",
        "print(\"Classification completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix and Performance Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "# Specify the path to the test images directory\n",
        "test_dir = '/content/gdrive/MyDrive/Ocular_Disease/sd_outputs/try'  # Directory where test images are stored\n",
        "\n",
        "# Load the dataset CSV file which contains the true labels for the test images\n",
        "dataset_file = '/content/gdrive/MyDrive/Ocular_Disease/true_labels.csv'\n",
        "df = pd.read_csv(dataset_file)  # Read the CSV into a DataFrame\n",
        "\n",
        "# Extract the image filenames and true labels from the dataset\n",
        "image_files = df['image'].values  # List of image filenames\n",
        "true_labels = df['true_label'].values  # List of corresponding true labels\n",
        "\n",
        "# Create lists to store predictions and predicted labels\n",
        "predictions = []  # List to store model's raw predictions\n",
        "predicted_labels = []  # List to store the predicted class labels\n",
        "\n",
        "print(\"Performing inference on test images...\")\n",
        "\n",
        "# Perform inference for each image in the directory\n",
        "for i, image_file in enumerate(image_files):\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Processing image {i+1}/{len(image_files)}\")\n",
        "    \n",
        "    # Load and preprocess the test image\n",
        "    image_path = os.path.join(test_dir, image_file)  # Get the full image path\n",
        "    img = image.load_img(image_path, target_size=(224, 224))  # Load and resize the image\n",
        "    x = image.img_to_array(img)  # Convert image to array\n",
        "    x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Perform the inference (predict the class for the image)\n",
        "    prediction = model.predict(x)  # Get the model's output\n",
        "    predicted_label_index = np.argmax(prediction)  # Get index of the predicted class (class with highest probability)\n",
        "    predicted_label = class_labels[predicted_label_index]  # Convert index to class label\n",
        "\n",
        "    # Append the prediction and predicted label to the respective lists\n",
        "    predictions.append(prediction)  # Store raw prediction\n",
        "    predicted_labels.append(predicted_label)  # Store predicted class label\n",
        "\n",
        "# Convert the lists to numpy arrays for easier processing later\n",
        "predictions = np.array(predictions)  # Convert list of raw predictions to numpy array\n",
        "predicted_labels = np.array(predicted_labels)  # Convert list of predicted labels to numpy array\n",
        "\n",
        "print(\"Inference completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the matrix to percentages\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)  # Plot the confusion matrix as an image\n",
        "    plt.title(title)  # Set the title for the plot\n",
        "    plt.colorbar()  # Add a color bar\n",
        "    tick_marks = np.arange(len(classes))  # Set tick marks based on the number of classes\n",
        "    plt.xticks(tick_marks, classes, rotation=45)  # Set x-axis labels with class names\n",
        "    plt.yticks(tick_marks, classes)  # Set y-axis labels with class names\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'  # Format values as percentage or integer\n",
        "    thresh = cm.max() / 2.  # Determine threshold for text color based on matrix values\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):  # Loop over matrix cells\n",
        "        plt.text(j, i, format(cm[i, j], fmt),  # Annotate matrix with values\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")  # Use white or black text for contrast\n",
        "\n",
        "    plt.tight_layout()  # Ensure everything fits without overlap\n",
        "    plt.ylabel('True label')  # Label for the y-axis\n",
        "    plt.xlabel('Predicted label')  # Label for the x-axis\n",
        "\n",
        "# Compute the confusion matrix comparing true labels vs predicted labels\n",
        "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix for the true vs predicted labels\n",
        "plt.figure(figsize=(10, 5))  # Set the figure size\n",
        "plt.grid(False)  # Disable grid lines\n",
        "plot_confusion_matrix(conf_mat, classes=['glaucoma', 'cataract', 'hyper', 'myopia', 'amd'], normalize=False)\n",
        "plt.title('ResNet50 Synthetic Data Classification - Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a classification report which includes precision, recall, and F1-score\n",
        "report = classification_report(\n",
        "    true_labels, predicted_labels,  # Actual labels and predicted labels\n",
        "    target_names=['glaucoma', 'cataract', 'hyper', 'myopia', 'amd']  # Class names\n",
        ")\n",
        "\n",
        "print(\"ResNet50 Synthetic Data Classification Report:\")\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
