{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries for ResNet traditional data augmentation\n",
        "import os  \n",
        "import re  \n",
        "import cv2  \n",
        "import random  \n",
        "import numpy as np  \n",
        "import pandas as pd  \n",
        "import tensorflow as tf \n",
        "\n",
        "# Try to import tensorflow_addons, if not available, define alternative metrics\n",
        "try:\n",
        "    import tensorflow_addons as tfa\n",
        "    HAS_TFA = True\n",
        "except ImportError:\n",
        "    print(\"Warning: tensorflow_addons not available. Using alternative F1 score implementation.\")\n",
        "    HAS_TFA = False\n",
        "    \n",
        "    # Define a simple F1 score metric as alternative\n",
        "    class F1Score(tf.keras.metrics.Metric):\n",
        "        def __init__(self, num_classes, average='weighted', name='f1', **kwargs):\n",
        "            super(F1Score, self).__init__(name=name, **kwargs)\n",
        "            self.num_classes = num_classes\n",
        "            self.average = average\n",
        "            self.precision = tf.keras.metrics.Precision()\n",
        "            self.recall = tf.keras.metrics.Recall()\n",
        "            \n",
        "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "            y_pred = tf.argmax(y_pred, axis=1)\n",
        "            y_true = tf.argmax(y_true, axis=1)\n",
        "            self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "            self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "            \n",
        "        def result(self):\n",
        "            p = self.precision.result()\n",
        "            r = self.recall.result()\n",
        "            return 2 * (p * r) / (p + r + tf.keras.backend.epsilon())\n",
        "            \n",
        "        def reset_state(self):\n",
        "            self.precision.reset_state()\n",
        "            self.recall.reset_state()\n",
        "\n",
        "# Setting the path to the directory containing preprocessed images\n",
        "DATA_PATH = \"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images\"\n",
        "\n",
        "# Defining the target image size for resizing images\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Loading the dataset from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv(\"/kaggle/input/ocular-disease-recognition-odir5k/full_df.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapping of short class labels to their full descriptive names\n",
        "class_short2full = {\n",
        "    \"G\": \"Glaucoma\",  # Short label 'G' represents Glaucoma\n",
        "    \"C\": \"Cataract\",  # Short label 'C' represents Cataract\n",
        "    \"A\": \"Age Related Macular Degeneration\",  # Short label 'A' represents ARMD\n",
        "    \"H\": \"Hypertension\",  # Short label 'H' represents Hypertension\n",
        "    \"M\": \"Myopia\"  # Short label 'M' represents Myopia\n",
        "}\n",
        "\n",
        "# Mapping of short class labels to numerical indices for machine learning models\n",
        "class_dict = {\n",
        "    \"G\": 0,  # Glaucoma is assigned index 0\n",
        "    \"C\": 1,  # Cataract is assigned index 1\n",
        "    \"A\": 2,  # ARMD is assigned index 2\n",
        "    \"H\": 3,  # Hypertension is assigned index 3\n",
        "    \"M\": 4   # Myopia is assigned index 4\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing and converting class labels\n",
        "data[\"class\"] = data[\"labels\"].apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
        "\n",
        "CLASSES = [\"G\", \"C\", \"A\", \"H\", \"M\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a dictionary mapping each class to a list of image filenames\n",
        "dict_img_list = {\n",
        "    class_: data.loc[data[\"class\"] == class_][\"filename\"].values\n",
        "    for class_ in class_short2full.keys()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced function to create a dataset by processing images from the given list\n",
        "# Supports traditional augmentations (flipping, rotation, brightness, contrast) for ResNet training\n",
        "\n",
        "def create_augmented_dataset(img_list, class_label, max_images, augment_factor=3):\n",
        "    dataset = []  # Initialize an empty list to store processed images and their labels\n",
        "    count = 0  # Counter to track the number of processed images\n",
        "\n",
        "    # Loop through each image in the provided list\n",
        "    for img in img_list:\n",
        "        # Stop processing if the max_images limit is reached\n",
        "        if max_images is not None and count >= max_images:\n",
        "            break\n",
        "\n",
        "        # Construct the full image path and read the image\n",
        "        image_path = os.path.join(DATA_PATH, img)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Skip if the image couldn't be loaded\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Convert the image to RGB format and resize to the target size\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        # Add the original image\n",
        "        dataset.append([np.array(image), class_label])\n",
        "        count += 1\n",
        "\n",
        "        # Apply traditional augmentations\n",
        "        if augment_factor > 0:\n",
        "            for _ in range(augment_factor):\n",
        "                # Horizontal flip\n",
        "                flipped_h = cv2.flip(image, 1)\n",
        "                dataset.append([np.array(flipped_h), class_label])\n",
        "                \n",
        "                # Vertical flip\n",
        "                flipped_v = cv2.flip(image, 0)\n",
        "                dataset.append([np.array(flipped_v), class_label])\n",
        "                \n",
        "                # Rotation (90 degrees)\n",
        "                rotated = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "                dataset.append([np.array(rotated), class_label])\n",
        "                \n",
        "                # Brightness adjustment\n",
        "                brightened = cv2.convertScaleAbs(image, alpha=1.2, beta=20)\n",
        "                dataset.append([np.array(brightened), class_label])\n",
        "                \n",
        "                # Contrast adjustment\n",
        "                contrasted = cv2.convertScaleAbs(image, alpha=1.3, beta=0)\n",
        "                dataset.append([np.array(contrasted), class_label])\n",
        "                \n",
        "                count += 5\n",
        "\n",
        "    # Shuffle the dataset to randomize the order of images\n",
        "    random.shuffle(dataset)\n",
        "\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset preparation for different ocular disease classes with traditional augmentations\n",
        "# Initialize lists to store the datasets for each class\n",
        "\n",
        "dataset_G = []  # Glaucoma dataset\n",
        "dataset_C = []  # Cataract dataset  \n",
        "dataset_A = []  # AMD dataset\n",
        "dataset_H = []  # Hypertension dataset\n",
        "dataset_M = []  # Myopia dataset\n",
        "\n",
        "# Process each class with traditional augmentations\n",
        "for i, class_ in enumerate(CLASSES):\n",
        "    img_list = dict_img_list[class_]  # Get the list of images for the current class\n",
        "    class_label = class_dict[class_]  # Get the class label\n",
        "    \n",
        "    print(f\"Processing {class_short2full[class_]} with traditional augmentations...\")\n",
        "    \n",
        "    if class_ == \"G\":\n",
        "        dataset_G = create_augmented_dataset(img_list, class_label, 284, augment_factor=2)\n",
        "    elif class_ == \"C\":\n",
        "        dataset_C = create_augmented_dataset(img_list, class_label, 293, augment_factor=2)\n",
        "    elif class_ == \"A\":\n",
        "        dataset_A = create_augmented_dataset(img_list, class_label, 266, augment_factor=2)\n",
        "    elif class_ == \"H\":\n",
        "        dataset_H = create_augmented_dataset(img_list, class_label, 128, augment_factor=2)\n",
        "    elif class_ == \"M\":\n",
        "        dataset_M = create_augmented_dataset(img_list, class_label, 232, augment_factor=2)\n",
        "    \n",
        "    print(f\"Completed {class_short2full[class_]} - Total samples: {len(eval(f'dataset_{class_}'))}\")\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"\\nDataset sizes after traditional augmentation:\")\n",
        "print(f\"Glaucoma: {len(dataset_G)} samples\")\n",
        "print(f\"Cataract: {len(dataset_C)} samples\")\n",
        "print(f\"AMD: {len(dataset_A)} samples\")\n",
        "print(f\"Hypertension: {len(dataset_H)} samples\")\n",
        "print(f\"Myopia: {len(dataset_M)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all augmented datasets\n",
        "dataset = []\n",
        "dataset += dataset_G + dataset_C + dataset_A + dataset_M + dataset_H\n",
        "\n",
        "# Get the total number of samples in the combined dataset\n",
        "print(f\"Total augmented dataset size: {len(dataset)}\")\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "random.shuffle(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Parameters for data splitting\n",
        "image_size = 224\n",
        "num_classes = 5\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "\n",
        "# Preparing predictors and target variables\n",
        "train_x = np.array([i[0] for i in dataset]).reshape(-1, image_size, image_size, 3)\n",
        "train_y = np.array([i[1] for i in dataset])\n",
        "\n",
        "# Calculating the number of images for each split\n",
        "num_images = len(train_x)\n",
        "num_train = int(num_images * train_ratio)\n",
        "num_val = int(num_images * val_ratio)\n",
        "num_test = num_images - num_train - num_val\n",
        "\n",
        "# Splitting the dataset into train and remaining (validation + test)\n",
        "x_train, x_remaining, y_train, y_remaining = train_test_split(train_x, train_y, train_size=num_train, random_state=42)\n",
        "\n",
        "# Further splitting the remaining data into validation and test\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_remaining, y_remaining, test_size=num_test, random_state=42)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_val = to_categorical(y_val, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Print the number of images in each split\n",
        "print(f\"Number of images - Train: {len(x_train)}, Validation: {len(x_val)}, Test: {len(x_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet50 Model Training with Traditional Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the image size\n",
        "image_size = 224\n",
        "\n",
        "# Import necessary layers from TensorFlow Keras\n",
        "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D  \n",
        "from tensorflow.keras.applications import ResNet50  \n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Load the ResNet50 model pre-trained on ImageNet, excluding the top layer\n",
        "resnet = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Set all ResNet50 layers as trainable\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Import the Sequential API for model creation\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "# Initialize the Sequential model\n",
        "model = Sequential()\n",
        "# Add the ResNet50 model as a feature extractor (without the top layers)\n",
        "model.add(resnet)\n",
        "\n",
        "# Add Dropout layer to prevent overfitting (rate of 0.5)\n",
        "model.add(Dropout(0.5))\n",
        "# Add Global Average Pooling layer to reduce dimensionality of the output from ResNet50\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Flatten the pooled features for dense layer processing\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add BatchNormalization to standardize activations and improve training speed\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add a dense layer with 512 neurons and ReLU activation\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# Add another dense layer with 256 neurons and ReLU activation\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# Add a dense layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# Add the final output layer with 5 neurons for 5 classes, using softmax for multi-class classification\n",
        "model.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "# Display the summary of the model architecture\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the metrics to be tracked during training\n",
        "METRICS = [\n",
        "    tf.keras.metrics.AUC(name=\"auc\"),  # Area under the ROC curve metric\n",
        "    tf.keras.metrics.CategoricalAccuracy(name=\"acc\"),  # Accuracy for categorical classification\n",
        "    tfa.metrics.F1Score(num_classes=5, average=\"weighted\", name=\"f1\"),  # F1 score, weighted average across all classes\n",
        "    tf.keras.metrics.AUC(name=\"prc\", curve=\"PR\"),  # Area under the Precision-Recall curve\n",
        "]\n",
        "\n",
        "# Compile the model with Adam optimizer, categorical crossentropy loss, and the specified metrics\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Adam optimizer with a learning rate\n",
        "    loss=\"categorical_crossentropy\",  # Loss function for multi-class classification\n",
        "    metrics=METRICS  # List of metrics to evaluate during training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the number of epochs for training\n",
        "epochs = 50\n",
        "\n",
        "# Import necessary callback modules from TensorFlow Keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Reduce learning rate on plateau callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    factor=0.5,  # Multiplies the learning rate by this factor when activated\n",
        "    patience=15,  # Number of epochs to wait for improvement before reducing LR\n",
        "    verbose=1,  # Print messages when learning rate is reduced\n",
        "    min_delta=0.0001,  # Minimum change to qualify as an improvement\n",
        "    cooldown=0,  # Number of epochs to wait before resuming normal learning rate\n",
        "    min_lr=1e-7,  # Minimum learning rate, prevents LR from going below this value\n",
        ")\n",
        "\n",
        "# EarlyStopping callback\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=epochs // 5,  # Number of epochs without improvement before stopping\n",
        "    restore_best_weights=True,  # Restore model weights from the epoch with the best performance\n",
        "    verbose=1,  # Print messages when early stopping is triggered\n",
        ")\n",
        "\n",
        "# ModelCheckpoint callback\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"/kaggle/working/resnet_traditional_aug_model.h5\", save_best_only=True)\n",
        "\n",
        "# List of callbacks to be used during model training\n",
        "callbacks = [checkpoint_cb, early_stopping_cb, reduce_lr]\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=epochs, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "print(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the augmented training data for future use\n",
        "np.save('/kaggle/working/x_train_traditional_aug.npy', x_train)\n",
        "np.save('/kaggle/working/y_train_traditional_aug.npy', y_train)\n",
        "\n",
        "np.save('/kaggle/working/x_val_traditional_aug.npy', x_val)\n",
        "np.save('/kaggle/working/y_val_traditional_aug.npy', y_val)\n",
        "\n",
        "np.save('/kaggle/working/x_test_traditional_aug.npy', x_test)\n",
        "np.save('/kaggle/working/y_test_traditional_aug.npy', y_test)\n",
        "\n",
        "print(\"Traditional augmented datasets saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
