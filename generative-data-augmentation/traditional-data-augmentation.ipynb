{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.260741Z",
     "iopub.status.busy": "2023-09-20T14:37:32.260372Z",
     "iopub.status.idle": "2023-09-20T14:37:32.305014Z",
     "shell.execute_reply": "2023-09-20T14:37:32.304119Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.260706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os  \n",
    "import re  \n",
    "import cv2  \n",
    "import random  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import tensorflow as tf \n",
    "\n",
    "# Setting the path to the directory containing preprocessed images\n",
    "DATA_PATH = \"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images\"\n",
    "\n",
    "# Defining the target image size for resizing images\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Loading the dataset from a CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(\"/kaggle/input/ocular-disease-recognition-odir5k/full_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.307577Z",
     "iopub.status.busy": "2023-09-20T14:37:32.307223Z",
     "iopub.status.idle": "2023-09-20T14:37:32.313605Z",
     "shell.execute_reply": "2023-09-20T14:37:32.312745Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.307544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mapping of short class labels to their full descriptive names\n",
    "class_short2full = {\n",
    "    \"G\": \"Glaucoma\",  # Short label 'G' represents Glaucoma\n",
    "    \"C\": \"Cataract\",  # Short label 'C' represents Cataract\n",
    "    \"A\": \"Age Related Macular Degeneration\",  # Short label 'A' represents ARMD\n",
    "    \"H\": \"Hypertension\",  # Short label 'H' represents Hypertension\n",
    "    \"M\": \"Myopia\"  # Short label 'M' represents Myopia\n",
    "}\n",
    "\n",
    "# Mapping of short class labels to numerical indices for machine learning models\n",
    "class_dict = {\n",
    "    \"G\": 0,  # Glaucoma is assigned index 0\n",
    "    \"C\": 1,  # Cataract is assigned index 1\n",
    "    \"A\": 2,  # ARMD is assigned index 2\n",
    "    \"H\": 3,  # Hypertension is assigned index 3\n",
    "    \"M\": 4   # Myopia is assigned index 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.315775Z",
     "iopub.status.busy": "2023-09-20T14:37:32.314949Z",
     "iopub.status.idle": "2023-09-20T14:37:32.338807Z",
     "shell.execute_reply": "2023-09-20T14:37:32.337892Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.315741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and converting class labels\n",
    "data[\"class\"] = data[\"labels\"].apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\n",
    "CLASSES = [\"G\", \"C\", \"A\", \"H\", \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.341778Z",
     "iopub.status.busy": "2023-09-20T14:37:32.341314Z",
     "iopub.status.idle": "2023-09-20T14:37:32.349158Z",
     "shell.execute_reply": "2023-09-20T14:37:32.348060Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.341743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary mapping each class to a list of image filenames\n",
    "# For each class in class_short2full.keys(), filter the dataset where \"class\" matches the class label\n",
    "# Extract the \"filename\" column values and store them as a NumPy array in the dictionary\n",
    "\n",
    "dict_img_list = {\n",
    "    class_: data.loc[data[\"class\"] == class_][\"filename\"].values  # Extract filenames for each class\n",
    "    for class_ in class_short2full.keys()  # Iterate over all defined classes\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.371931Z",
     "iopub.status.busy": "2023-09-20T14:37:32.371543Z",
     "iopub.status.idle": "2023-09-20T14:37:32.383291Z",
     "shell.execute_reply": "2023-09-20T14:37:32.382122Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.371894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to create a dataset by processing images from the given list\n",
    "# Supports augmentations (e.g., flipping, rotation) if specified\n",
    "\n",
    "def create_dataset(img_list, class_label, max_images, augment={}):\n",
    "    dataset = []  # Initialize an empty list to store processed images and their labels\n",
    "    count = 0  # Counter to track the number of processed images\n",
    "\n",
    "    # Loop through each image in the provided list\n",
    "    for img in img_list:\n",
    "        # Stop processing if the max_images limit is reached\n",
    "        if max_images is not None and count >= max_images:\n",
    "            break\n",
    "\n",
    "        # Construct the full image path and read the image\n",
    "        image_path = os.path.join(DATA_PATH, img)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Skip if the image couldn't be loaded\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Convert the image to RGB format and resize to the target size\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Perform augmentations if the class label is in the augment dictionary\n",
    "        if augment and random.random() < 1:  # Ensure augmentation logic runs\n",
    "            for _ in range(3):  # Generate three augmented versions of the image\n",
    "                if class_label in augment.keys():\n",
    "                    # Apply left-right flip\n",
    "                    image_lr = tf.image.flip_left_right(image)\n",
    "                    # Apply up-down flip\n",
    "                    image_ud = tf.image.flip_up_down(image)\n",
    "                    # Apply 90-degree rotation\n",
    "                    image_rot90 = tf.image.rot90(image, k=1)\n",
    "\n",
    "                    # Append augmented images with their labels to the dataset\n",
    "                    dataset.append([np.array(image_lr), class_label])\n",
    "                    dataset.append([np.array(image_ud), class_label])\n",
    "                    dataset.append([np.array(image_rot90), class_label])\n",
    "\n",
    "                    count += 3  # Increment the counter for each augmentation\n",
    "\n",
    "        # Append the original image with its label to the dataset\n",
    "        dataset.append([np.array(image), class_label])\n",
    "        count += 1  # Increment the counter for the original image\n",
    "\n",
    "    # Shuffle the dataset to randomize the order of images\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    return dataset  # Return the prepared dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:37:32.385177Z",
     "iopub.status.busy": "2023-09-20T14:37:32.384794Z",
     "iopub.status.idle": "2023-09-20T14:37:40.699410Z",
     "shell.execute_reply": "2023-09-20T14:37:40.698415Z",
     "shell.execute_reply.started": "2023-09-20T14:37:32.385144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset preparation for different ocular disease classes, with augmentations and random shuffling\n",
    "# Initialize lists to store the datasets for each class\n",
    "\n",
    "dataset_G = []  \n",
    "augment_G = {  # Set augmentation flag for Glaucoma class (class 0)\n",
    "    class_dict[\"G\"]: True,\n",
    "}\n",
    "\n",
    "# Loop through each class for Glaucoma (CLASSES[0]) and generate the dataset\n",
    "for i, class_ in enumerate(CLASSES[0]):\n",
    "    img_list = dict_img_list[class_]  # Get the list of images for the current class\n",
    "    dataset_G += create_dataset(img_list, 0, 284, augment_G)  # Create and add to the dataset\n",
    "\n",
    "    random.shuffle(dataset_G)  # Shuffle the dataset to randomize the order\n",
    "\n",
    "###### \n",
    "dataset_C = []  \n",
    "augment_C = {  # Set augmentation flag for Cataract class (class 1)\n",
    "    class_dict[\"C\"]: True,\n",
    "}\n",
    "\n",
    "# Loop through each class for Cataract (CLASSES[1]) and generate the dataset\n",
    "for i, class_ in enumerate(CLASSES[1]):\n",
    "    img_list = dict_img_list[class_]\n",
    "    dataset_C += create_dataset(img_list, 1, 293, augment_C)\n",
    "\n",
    "    random.shuffle(dataset_C)\n",
    "\n",
    "###########\n",
    "dataset_A = []  \n",
    "augment_A = {  # Set augmentation flag for Age Related Macular Degeneration class (class 2)\n",
    "    class_dict[\"A\"]: True,\n",
    "}\n",
    "\n",
    "# Loop through each class for Age Related Macular Degeneration (CLASSES[2]) and generate the dataset\n",
    "for i, class_ in enumerate(CLASSES[2]):\n",
    "    img_list = dict_img_list[class_]\n",
    "    dataset_A += create_dataset(img_list, 2, 266, augment_A)\n",
    "\n",
    "    random.shuffle(dataset_A)\n",
    "\n",
    "###########\n",
    "dataset_H = []  \n",
    "augment_H = {  # Set augmentation flag for Hypertension class (class 3)\n",
    "    class_dict[\"H\"]: True,\n",
    "}\n",
    "\n",
    "# Loop through each class for Hypertension (CLASSES[3]) and generate the dataset\n",
    "for i, class_ in enumerate(CLASSES[3]):\n",
    "    img_list = dict_img_list[class_]\n",
    "    dataset_H += create_dataset(img_list, 3, 128, augment_H)\n",
    "\n",
    "    random.shuffle(dataset_H)\n",
    "###########\n",
    "dataset_M = []  \n",
    "augment_M = {  # Set augmentation flag for Myopia class (class 4)\n",
    "    class_dict[\"M\"]: True,\n",
    "}\n",
    "\n",
    "# Loop through each class for Myopia (CLASSES[4]) and generate the dataset\n",
    "for i, class_ in enumerate(CLASSES[4]):\n",
    "    img_list = dict_img_list[class_]\n",
    "    dataset_M += create_dataset(img_list, 4, 232, augment_M)\n",
    "\n",
    "    random.shuffle(dataset_M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:38:19.568214Z",
     "iopub.status.busy": "2023-09-20T14:38:19.567806Z",
     "iopub.status.idle": "2023-09-20T14:38:19.575807Z",
     "shell.execute_reply": "2023-09-20T14:38:19.574769Z",
     "shell.execute_reply.started": "2023-09-20T14:38:19.568177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "H=len(dataset_H)\n",
    "M=len(dataset_M)\n",
    "A=len(dataset_A)\n",
    "G=len(dataset_G)\n",
    "C=len(dataset_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:38:36.629565Z",
     "iopub.status.busy": "2023-09-20T14:38:36.629088Z",
     "iopub.status.idle": "2023-09-20T14:38:36.636541Z",
     "shell.execute_reply": "2023-09-20T14:38:36.635391Z",
     "shell.execute_reply.started": "2023-09-20T14:38:36.629524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Combine datasets from all classes (Glaucoma, Hypertension, Age Related Macular Degeneration, Myopia, Cataract)\n",
    "dataset = []\n",
    "dataset += dataset_G + dataset_H + dataset_A + dataset_M + dataset_C\n",
    "\n",
    "# Get the total number of samples in the combined dataset\n",
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-20T14:40:33.685204Z",
     "iopub.status.busy": "2023-09-20T14:40:33.684123Z",
     "iopub.status.idle": "2023-09-20T14:40:33.940837Z",
     "shell.execute_reply": "2023-09-20T14:40:33.939986Z",
     "shell.execute_reply.started": "2023-09-20T14:40:33.685159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose a random image\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "image, class_label = dataset[random_index]\n",
    "\n",
    "# View image\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Class: {class_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.761627Z",
     "iopub.status.idle": "2023-09-20T14:37:40.762053Z",
     "shell.execute_reply": "2023-09-20T14:37:40.761853Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.761831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Parameters\n",
    "image_size = 224\n",
    "num_classes = 5\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "# Preparing predictors and target variables\n",
    "train_x = np.array([i[0] for i in dataset]).reshape(-1, image_size, image_size, 3)\n",
    "train_y = np.array([i[1] for i in dataset])\n",
    "\n",
    "# Calculating the number of images for each split\n",
    "num_images = len(train_x)\n",
    "num_train = int(num_images * train_ratio)\n",
    "num_val = int(num_images * val_ratio)\n",
    "num_test = num_images - num_train - num_val\n",
    "\n",
    "# Splitting the dataset into train and remaining (validation + test)\n",
    "x_train, x_remaining, y_train, y_remaining = train_test_split(train_x, train_y, train_size=num_train, random_state=42)\n",
    "\n",
    "# Further splitting the remaining data into validation and test\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_remaining, y_remaining, test_size=num_test, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Print the number of images in each split\n",
    "print(f\"Number of images - Train: {len(x_train)}, Validation: {len(x_val)}, Test: {len(x_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.764618Z",
     "iopub.status.idle": "2023-09-20T14:37:40.765057Z",
     "shell.execute_reply": "2023-09-20T14:37:40.764848Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.764828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.770788Z",
     "iopub.status.idle": "2023-09-20T14:37:40.771334Z",
     "shell.execute_reply": "2023-09-20T14:37:40.771125Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.771102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the target labels into categorical (one-hot encoded) format for each dataset split\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)  # One-hot encoding for training labels\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)  # One-hot encoding for validation labels\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)  # One-hot encoding for test labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.774658Z",
     "iopub.status.idle": "2023-09-20T14:37:40.775003Z",
     "shell.execute_reply": "2023-09-20T14:37:40.774855Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.774839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_val:\", x_val.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.776814Z",
     "iopub.status.idle": "2023-09-20T14:37:40.777281Z",
     "shell.execute_reply": "2023-09-20T14:37:40.777052Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.777031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the test set\n",
    "test_class_counts = np.bincount(y_train_labels)\n",
    "\n",
    "# Print the number of images for each class in the test set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.779213Z",
     "iopub.status.idle": "2023-09-20T14:37:40.779663Z",
     "shell.execute_reply": "2023-09-20T14:37:40.779454Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.779433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the combined training data for future use\n",
    "np.save('/kaggle/working/x_train_0-5.npy', x_train)\n",
    "np.save('/kaggle/working/y_train_0-5.npy', y_train)\n",
    "\n",
    "np.save('/kaggle/working/x_val_0-5.npy', x_val)\n",
    "np.save('/kaggle/working/y_val_0-5.npy', y_val)\n",
    "\n",
    "np.save('/kaggle/working/x_test_0-5.npy', x_test)\n",
    "np.save('/kaggle/working/y_test_0-5.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-20T14:37:40.781529Z",
     "iopub.status.idle": "2023-09-20T14:37:40.782126Z",
     "shell.execute_reply": "2023-09-20T14:37:40.781891Z",
     "shell.execute_reply.started": "2023-09-20T14:37:40.781869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print( y_train.shape, type(y_train))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 611716,
     "sourceId": 1512919,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
