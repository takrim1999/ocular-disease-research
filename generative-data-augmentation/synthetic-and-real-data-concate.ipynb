{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:31.630362Z",
     "iopub.status.busy": "2023-09-27T16:09:31.629813Z",
     "iopub.status.idle": "2023-09-27T16:09:42.789574Z",
     "shell.execute_reply": "2023-09-27T16:09:42.788435Z",
     "shell.execute_reply.started": "2023-09-27T16:09:31.630326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.792639Z",
     "iopub.status.busy": "2023-09-27T16:09:42.791685Z",
     "iopub.status.idle": "2023-09-27T16:09:42.814794Z",
     "shell.execute_reply": "2023-09-27T16:09:42.813834Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.792600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the synthetic data from the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv(\"/kaggle/input/synthetic-data-csv/synthetic_data.csv\")\n",
    "\n",
    "# Display the first 30 rows of the DataFrame to get an overview of the dataset\n",
    "data.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.816417Z",
     "iopub.status.busy": "2023-09-27T16:09:42.816060Z",
     "iopub.status.idle": "2023-09-27T16:09:42.838730Z",
     "shell.execute_reply": "2023-09-27T16:09:42.837655Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.816382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# List of full class labels\n",
    "labels_long = [\"Diabet\", \"Glaucoma\", \"Cataract\", \"AMD\", \"Hypertension\", \"Myopia\", \"Normal\"]\n",
    "\n",
    "# Create short class labels by taking the first letter of each full label\n",
    "labels_short = [ll[0] for ll in labels_long]\n",
    "\n",
    "# Mapping of short labels to full labels (e.g., 'D' -> 'Diabet')\n",
    "class_short2full = {\n",
    "    ls: ll\n",
    "    for ls, ll in zip(labels_short, labels_long)\n",
    "}\n",
    "\n",
    "# Create a dictionary that maps each short class label to a unique integer (for encoding)\n",
    "class_dict = {class_: i for i, class_ in enumerate(class_short2full.keys())}\n",
    "\n",
    "# Reverse dictionary that maps each integer back to the short class label (for decoding)\n",
    "class_dict_rev = {v: k for k, v in class_dict.items()}\n",
    "\n",
    "# Total number of unique classes (in this case 7)\n",
    "NUM_CLASSES = len(class_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.843978Z",
     "iopub.status.busy": "2023-09-27T16:09:42.842865Z",
     "iopub.status.idle": "2023-09-27T16:09:42.851296Z",
     "shell.execute_reply": "2023-09-27T16:09:42.850141Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.843939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Class label mapping (short label -> full label)\n",
    "class_short2full = {\n",
    "    \"D\": \"Diabet\",          # 'D' -> 'Diabet'\n",
    "    \"G\": \"Glaucoma\",        # 'G' -> 'Glaucoma'\n",
    "    \"C\": \"Cataract\",        # 'C' -> 'Cataract'\n",
    "    \"A\": \"AMD\",             # 'A' -> 'AMD' (Age-related Macular Degeneration)\n",
    "    \"H\": \"Hypertension\",    # 'H' -> 'Hypertension'\n",
    "    \"M\": \"Myopia\",          # 'M' -> 'Myopia'\n",
    "    \"N\": \"Normal\"           # 'N' -> 'Normal'\n",
    "}\n",
    "\n",
    "# Class ID mapping (short label -> class ID)\n",
    "class_dict = {\n",
    "    \"D\": 0,                 # 'D' -> 0 (Diabet)\n",
    "    \"G\": 1,                 # 'G' -> 1 (Glaucoma)\n",
    "    \"C\": 2,                 # 'C' -> 2 (Cataract)\n",
    "    \"A\": 3,                 # 'A' -> 3 (AMD)\n",
    "    \"H\": 4,                 # 'H' -> 4 (Hypertension)\n",
    "    \"M\": 5,                 # 'M' -> 5 (Myopia)\n",
    "    \"N\": 6                  # 'N' -> 6 (Normal)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.854523Z",
     "iopub.status.busy": "2023-09-27T16:09:42.853859Z",
     "iopub.status.idle": "2023-09-27T16:09:42.869166Z",
     "shell.execute_reply": "2023-09-27T16:09:42.868129Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.854492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Define color palette for different plot elements\n",
    "COLORS = {\n",
    "    \"fig_bg\": \"#f6f5f5\",              # Background color of the figure\n",
    "    \"plot_neut\": \"#ddbea9\",           # Neutral color for plots\n",
    "    \"plot_text\": \"#343a40\",           # Text color for plots\n",
    "    \n",
    "    # A list of colors for plotting (for different categories or groups)\n",
    "    \"cmap_color_list\": [\"#001219\", \"#005F73\", \"#0A9396\", \"#94D2BD\", \"#E9D8A6\",\n",
    "                        \"#EE9B00\", \"#CA6702\", \"#BB3E03\", \"#AE2012\", \"#9B2226\"],\n",
    "    \n",
    "    # Colors for different splits of data\n",
    "    \"split\": {\n",
    "        \"train\": \"#264653\",          # Training data color\n",
    "        \"val\": \"#2a9d8f\",            # Validation data color\n",
    "        \"test\": \"#e9c46a\"            # Test data color\n",
    "    }\n",
    "}\n",
    "\n",
    "# Assign colors to each class from the 'class_short2full' dictionary\n",
    "# 'class_short2full' contains the mapping from short class labels to full names\n",
    "COLORS[\"class\"] = {ls: c for ls, c in zip(class_short2full.keys(), COLORS[\"cmap_color_list\"][:len(class_short2full.keys())])}\n",
    "\n",
    "# Define color maps for plots, from a list of color codes\n",
    "COLORS[\"cmap\"] = mpl.colors.LinearSegmentedColormap.from_list(\"\", COLORS[\"cmap_color_list\"])\n",
    "COLORS[\"cmap_pos\"] = mpl.colors.LinearSegmentedColormap.from_list(\"\", [\"#F0F3F8\", \"#D1DBE9\", \"#A2B7D2\", \"#7493BC\", \"#6487B4\", \"#3D5A80\"])\n",
    "\n",
    "# List of colors associated with each class for easy access\n",
    "colors_class_list = list(COLORS[\"class\"].values())\n",
    "\n",
    "# Font settings for various plot titles, labels, and texts\n",
    "FONT_KW = {\n",
    "    \"plot_title\" : {                # Font settings for main plot title\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"25\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_title_small\" : {          # Font settings for smaller plot title\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"16\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_subtitle\" : {             # Font settings for plot subtitle\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"12\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"subplot_title\" : {             # Font settings for subplot title\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"18\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"subplot_title_small\" : {       # Font settings for smaller subplot title\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"12\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_label\" : {                # Font settings for plot labels\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"16\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_label_small\" : {          # Font settings for smaller plot labels\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"bold\",           # Bold text\n",
    "        \"size\": \"12\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_text\" : {                 # Font settings for general plot text\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"normal\",         # Normal weight\n",
    "        \"size\": \"12\",               # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "    \"plot_text_small\" : {           # Font settings for smaller plot text\n",
    "        \"fontname\": \"serif\",        # Font type (serif)\n",
    "        \"weight\": \"normal\",         # Normal weight\n",
    "        \"size\": \"8\",                # Font size\n",
    "        \"style\": \"normal\"           # Normal style\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.871871Z",
     "iopub.status.busy": "2023-09-27T16:09:42.871544Z",
     "iopub.status.idle": "2023-09-27T16:09:42.895842Z",
     "shell.execute_reply": "2023-09-27T16:09:42.894928Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.871846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to count unique values and return their relative frequency as percentages\n",
    "def count_values_relative(y):\n",
    "    bins, vals = np.unique(y, return_counts=True)  # Get unique values and their counts\n",
    "    return bins, 100 * vals / np.sum(vals)         # Return values and their relative frequencies in percentages\n",
    "\n",
    "# Function to round up a number to the nearest multiple of 'd' (default 1000)\n",
    "def ceil_d(n, d=1000):\n",
    "    return int(np.ceil(n / d) * d)  # Round up 'n' to the nearest multiple of 'd'\n",
    "\n",
    "# Function to compute subplot dimensions given 'N' total subplots\n",
    "def get_subplot_dims(N):\n",
    "    r = np.ceil(np.sqrt(N))  # Rows (sqrt of N, rounded up)\n",
    "    c = np.floor(np.sqrt(N))  # Columns (sqrt of N, rounded down)\n",
    "    if r*c < N:  # If the grid is too small to fit all subplots\n",
    "        r += 1  # Increase the number of rows\n",
    "    return int(r), int(c)  # Return number of rows and columns\n",
    "\n",
    "# Function to convert a text to an integer if possible, else return the text\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text  # Convert to integer if it's a digit\n",
    "\n",
    "# Function to split a string into parts that can be naturally sorted (numerical sorting)\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]  # Split and sort text based on numeric values\n",
    "\n",
    "# Function to return unique sorted values in a column, sorted naturally, with handling of missing values\n",
    "def natural_sort_col_unique(df, colname, missing=\"NA\"):\n",
    "    arr = df[colname].unique().tolist()  # Get unique values from the column\n",
    "    if np.nan in arr:  # Handle NaN values in the column\n",
    "        arr[arr.index(np.nan)] = missing  # Replace NaN with 'missing'\n",
    "    arr.sort(key=natural_keys)  # Sort values naturally (handling numbers within strings)\n",
    "    return arr  # Return sorted list of unique values\n",
    "\n",
    "# Function to calculate conditional entropy H(x | y)\n",
    "def conditional_entropy(x, y):\n",
    "    y_counter = Counter(y)  # Count occurrences of each value in y\n",
    "    xy_counter = Counter(list(zip(x, y)))  # Count occurrences of pairs (x, y)\n",
    "    total_occurrences = sum(y_counter.values())  # Total number of occurrences in y\n",
    "    entropy = 0\n",
    "    for xy in xy_counter.keys():  # Loop through each (x, y) pair\n",
    "        p_xy = xy_counter[xy] / total_occurrences  # Probability of (x, y) pair\n",
    "        p_y = y_counter[xy[1]] / total_occurrences  # Probability of y\n",
    "        entropy += p_xy * math.log(p_y / p_xy)  # Compute conditional entropy\n",
    "    return entropy\n",
    "\n",
    "# Function to calculate Theil's U statistic (a measure of association between two variables)\n",
    "def theil_u(x, y):\n",
    "    s_xy = conditional_entropy(x, y)  # Conditional entropy H(x | y)\n",
    "    x_counter = Counter(x)  # Count occurrences of each value in x\n",
    "    total_occurrences = sum(x_counter.values())  # Total number of occurrences in x\n",
    "    p_x = list(map(lambda n: n / total_occurrences, x_counter.values()))  # Probability of each value in x\n",
    "    s_x = ss.entropy(p_x)  # Entropy of x\n",
    "    if s_x == 0:  # If entropy of x is 0 (no variation in x), return 1\n",
    "        return 1\n",
    "    else:\n",
    "        # Calculate Theil's U: (S(x) - S(x | y)) / S(x)\n",
    "        return (s_x - s_xy) / s_x\n",
    "    \n",
    "# Function to calculate the correlation ratio (eta-squared) between categories and continuous measurements\n",
    "def correlation_ratio(categories, measurements):\n",
    "    if isinstance(categories, pd.Series):\n",
    "        categories = categories.values  # Convert to numpy array if it's a pandas Series\n",
    "    if isinstance(measurements, pd.Series):\n",
    "        measurements = measurements.values  # Convert to numpy array if it's a pandas Series\n",
    "    fcat, _ = pd.factorize(categories)  # Factorize categories into integer labels\n",
    "    cat_num = np.max(fcat) + 1  # Number of unique categories\n",
    "    y_avg_array = np.zeros(cat_num)  # Array to store the average measurement for each category\n",
    "    n_array = np.zeros(cat_num)  # Array to store the count of measurements per category\n",
    "    for i in range(0, cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]  # Measurements for category i\n",
    "        n_array[i] = len(cat_measures)  # Number of measurements for category i\n",
    "        y_avg_array[i] = np.average(cat_measures)  # Average measurement for category i\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array, n_array)) / np.sum(n_array)  # Overall average\n",
    "    numerator = np.sum(\n",
    "        np.multiply(n_array, np.power(np.subtract(y_avg_array, y_total_avg), 2)))  # Between-group variance\n",
    "    denominator = np.sum(np.power(np.subtract(measurements, y_total_avg), 2))  # Total variance\n",
    "    if numerator == 0:  # If there is no variance between categories, eta = 0\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = np.sqrt(numerator / denominator)  # Correlation ratio (square root of eta-squared)\n",
    "    return eta  # Return the correlation ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.897867Z",
     "iopub.status.busy": "2023-09-27T16:09:42.897241Z",
     "iopub.status.idle": "2023-09-27T16:09:42.909152Z",
     "shell.execute_reply": "2023-09-27T16:09:42.908125Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.897834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "DATA_PATH = \"/kaggle/input/synthetic-data/synthetic_data\"  # Path to the synthetic data\n",
    "IMG_SIZE = 224  \n",
    "IMAGE_SIZE = [IMG_SIZE, IMG_SIZE]\n",
    "\n",
    "# Function to convert a class index into a one-hot encoded label\n",
    "def label_image(c):\n",
    "    label = np.full((NUM_CLASSES), 0, dtype=int)  # Initialize an array of zeros of length NUM_CLASSES\n",
    "    label[c] = 1  # Set the label at index 'c' to 1 (one-hot encoding)\n",
    "    return label  # Return the one-hot encoded label\n",
    "\n",
    "# Function to calculate the shape of the Gaussian filter\n",
    "def get_gaussian_filter_shape(IMG_SIZE):\n",
    "    # The filter shape is roughly one-fourth of the image size, minus one\n",
    "    return IMG_SIZE // 4 - 1  # Return the computed filter size\n",
    "\n",
    "# Function to apply a Gaussian blur on an image\n",
    "def blur_image(image, sigma=10):\n",
    "    # Get the filter shape based on the image size\n",
    "    filter_shape = get_gaussian_filter_shape(IMG_SIZE)\n",
    "    # Apply the Gaussian filter to the image using TensorFlow Addons\n",
    "    return tfa.image.gaussian_filter2d(image, filter_shape=filter_shape, sigma=sigma)\n",
    "\n",
    "# Function to apply a weighted transformation on an image\n",
    "def weighted_image(image, alpha=4, beta=-4, gamma=128):\n",
    "    # Weighted sum of the original image, blurred image, and a constant gamma\n",
    "    return image * alpha + blur_image(image) * beta + gamma  # Return the weighted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.910820Z",
     "iopub.status.busy": "2023-09-27T16:09:42.910362Z",
     "iopub.status.idle": "2023-09-27T16:09:42.919356Z",
     "shell.execute_reply": "2023-09-27T16:09:42.918318Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.910786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a copy of the original dataframe for exploratory data analysis (EDA)\n",
    "df_eda = data.copy()  # This ensures that the original 'data' remains unmodified while we work with 'df_eda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.921952Z",
     "iopub.status.busy": "2023-09-27T16:09:42.921306Z",
     "iopub.status.idle": "2023-09-27T16:09:42.937527Z",
     "shell.execute_reply": "2023-09-27T16:09:42.936556Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.921920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract class labels from the 'labels' column and store them in a new 'class' column\n",
    "df_eda[\"class\"] = df_eda[\"labels\"].apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))\n",
    "\n",
    "# - `re.findall(\"[a-zA-Z]+\", x)`: This regular expression finds all sequences of alphabetic characters in the string `x`.\n",
    "# - `\" \".join(...)`: Joins the alphabetic sequences found by `re.findall` into a single string, separated by spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:09:42.944255Z",
     "iopub.status.busy": "2023-09-27T16:09:42.943991Z",
     "iopub.status.idle": "2023-09-27T16:09:44.685182Z",
     "shell.execute_reply": "2023-09-27T16:09:44.681194Z",
     "shell.execute_reply.started": "2023-09-27T16:09:42.944234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side (1 row, 2 columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 6), dpi=70, gridspec_kw={\"wspace\": 0.5})\n",
    "\n",
    "# Set background color of the figure\n",
    "fig.patch.set_facecolor(COLORS[\"fig_bg\"])\n",
    "\n",
    "# Count the occurrences of each class and calculate the percentage\n",
    "value_counts = df_eda[\"class\"].value_counts().rename(\"num\").to_frame()  # Class count\n",
    "value_counts[\"percent\"] = value_counts / value_counts.sum()  # Percentage for each class\n",
    "value_counts.reindex(index=COLORS[\"class\"].keys())  # Reindex based on class colors\n",
    "\n",
    "# Create horizontal bar plot for label-based class distribution\n",
    "b1 = ax1.barh(value_counts.index, value_counts[\"percent\"])\n",
    "\n",
    "# Set y-ticks with class names, apply font settings, and set label color\n",
    "ax1.set_yticks(value_counts.index, [class_short2full[i] for i in value_counts.index], **FONT_KW[\"plot_label\"], color=COLORS[\"plot_text\"])\n",
    "ax1.tick_params(axis=\"y\", length=0)  # Remove tick marks on y-axis\n",
    "ax1.set_title(\"Label-Based\", loc=\"left\", **FONT_KW[\"subplot_title\"], color=COLORS[\"plot_text\"], pad=30)  # Set title\n",
    "ax1.text(0, 8.2, \"(Multi-class)\", **FONT_KW[\"subplot_title_small\"], color=COLORS[\"plot_text\"])  # Subtitle for multi-class\n",
    "\n",
    "# Add labels to the bars with counts and percentages\n",
    "ax1.bar_label(b1, labels=[str(val) + f\"\\n({str(np.round(100*pcnt,1))}%)\" for val, pcnt in zip(value_counts[\"num\"], value_counts[\"percent\"])],\n",
    "              color=COLORS[\"plot_text\"], **FONT_KW[\"plot_text\"])\n",
    "\n",
    "# Set background color for the axes and adjust bar and label colors\n",
    "ax1.set_facecolor(COLORS[\"fig_bg\"])\n",
    "for i in range(NUM_CLASSES):\n",
    "    c = COLORS[\"class\"][value_counts.index[i]]\n",
    "    ax1.get_yticklabels()[i].set_color(c)  # Set color of the y-tick labels\n",
    "    b1[i].set_color(c)  # Set color of the bars\n",
    "\n",
    "# Hide x-axis for aesthetic purposes\n",
    "ax1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# Remove the spines from the top, right, and bottom of the plot\n",
    "for spine in [\"bottom\", \"right\", \"top\"]:\n",
    "    ax1.spines[spine].set_visible(False)\n",
    "\n",
    "#########################################################\n",
    "# Multiclass Multi-label part (based on diagnosis)\n",
    "\n",
    "# Sum the number of occurrences for each label across all rows and calculate percentage\n",
    "value_count_diag = df_eda[labels_short].sum().rename(\"num\").to_frame()\n",
    "value_count_diag[\"percent\"] = value_count_diag / df_eda.shape[0]  # Percentage of each diagnosis\n",
    "value_count_diag = value_count_diag.reindex(index=value_counts.index)  # Reindex based on original class ordering\n",
    "\n",
    "# Create horizontal bar plot for diagnosis-based class distribution\n",
    "b2 = ax2.barh(value_count_diag.index, value_count_diag[\"percent\"])\n",
    "\n",
    "# Set y-ticks with class names, apply font settings, and set label color\n",
    "ax2.set_yticks(value_count_diag.index, [class_short2full[i] for i in value_count_diag.index], **FONT_KW[\"plot_label\"], color=COLORS[\"plot_text\"])\n",
    "ax2.tick_params(axis=\"y\", length=0)  # Remove tick marks on y-axis\n",
    "ax2.set_title(\"Diagnosis-Based\", loc=\"left\", **FONT_KW[\"subplot_title\"], color=COLORS[\"plot_text\"], pad=30)  # Title for diagnosis-based\n",
    "ax2.text(0, 8.2, \"(Multi-class Multi-label)\", **FONT_KW[\"subplot_title_small\"], color=COLORS[\"plot_text\"])  # Subtitle for multi-label\n",
    "\n",
    "# Add labels to the bars with counts and percentages\n",
    "ax2.bar_label(b2, labels=[str(val) + f\"\\n({str(np.round(100*pcnt,1))}%)\" for val, pcnt in zip(value_count_diag[\"num\"], value_count_diag[\"percent\"])],\n",
    "              color=COLORS[\"plot_text\"], **FONT_KW[\"plot_text\"])\n",
    "\n",
    "# Set background color for the axes and adjust bar and label colors\n",
    "ax2.set_facecolor(COLORS[\"fig_bg\"])\n",
    "for i in range(NUM_CLASSES):\n",
    "    c = COLORS[\"class\"][value_count_diag.index[i]]\n",
    "    ax2.get_yticklabels()[i].set_color(c)  # Set color of the y-tick labels\n",
    "    b2[i].set_color(c)  # Set color of the bars\n",
    "\n",
    "# Hide x-axis for aesthetic purposes\n",
    "ax2.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# Remove the spines from the top, right, and bottom of the plot\n",
    "for spine in [\"bottom\", \"right\", \"top\"]:\n",
    "    ax2.spines[spine].set_visible(False)\n",
    "\n",
    "# Add the overall plot title\n",
    "plt.figtext(0, 1.05, \"Class Distribution\", **FONT_KW[\"plot_title\"], color=COLORS[\"plot_text\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.469871Z",
     "iopub.status.busy": "2023-09-27T16:10:04.469510Z",
     "iopub.status.idle": "2023-09-27T16:10:04.477028Z",
     "shell.execute_reply": "2023-09-27T16:10:04.475858Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.469845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the class labels and their corresponding counts\n",
    "for cls, num in zip(value_counts.index, value_counts[\"num\"]):\n",
    "    # Retrieve the full class name using the short class name (cls)\n",
    "    class_name = class_short2full[cls]\n",
    "    \n",
    "    # Print the full class name and its corresponding count\n",
    "    print(f\"{class_name}: {num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.480562Z",
     "iopub.status.busy": "2023-09-27T16:10:04.479605Z",
     "iopub.status.idle": "2023-09-27T16:10:04.495423Z",
     "shell.execute_reply": "2023-09-27T16:10:04.494158Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.480527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(value_counts.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.497767Z",
     "iopub.status.busy": "2023-09-27T16:10:04.497006Z",
     "iopub.status.idle": "2023-09-27T16:10:04.514921Z",
     "shell.execute_reply": "2023-09-27T16:10:04.513726Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.497734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply a lambda function to the \"labels\" column to extract only alphabetic characters and join them as a string\n",
    "data[\"class\"] = data[\"labels\"].apply(lambda x: \" \".join(re.findall(\"[a-zA-Z]+\", x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.518964Z",
     "iopub.status.busy": "2023-09-27T16:10:04.518686Z",
     "iopub.status.idle": "2023-09-27T16:10:04.534722Z",
     "shell.execute_reply": "2023-09-27T16:10:04.533512Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.518940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store image filenames categorized by class\n",
    "dict_img_list = {\n",
    "    class_: data.loc[data[\"class\"] == class_][\"filename\"].values  # Filter rows by class and get corresponding filenames\n",
    "    for class_ in class_short2full.keys()  # Iterate over each class in the class_short2full dictionary\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.538380Z",
     "iopub.status.busy": "2023-09-27T16:10:04.538063Z",
     "iopub.status.idle": "2023-09-27T16:10:04.553504Z",
     "shell.execute_reply": "2023-09-27T16:10:04.552298Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.538355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler  # Import the MinMaxScaler to normalize the input features\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage  # Import for adding images as annotations to the plot\n",
    "\n",
    "def plot_classes(X, y, min_distance=0.05, images=None, figsize=(13, 10), cmap=COLORS[\"cmap\"], annot=False):\n",
    "    # Scale the input features (X) so that they range from 0 to 1\n",
    "    X_normalized = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    # Initialize a list to store coordinates of the points plotted so far\n",
    "    # We start with a point far away from the data points to avoid unnecessary `if` statements later\n",
    "    neighbors = np.array([[10., 10.]])\n",
    "    \n",
    "    # Create a figure and axis for the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Get the unique class labels from `y`\n",
    "    classes = np.unique(y)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # Plot each class separately with a different color\n",
    "    for class_ in classes:\n",
    "        ax.scatter(\n",
    "            X_normalized[y == class_, 0],  # Select the x-coordinate for points of the current class\n",
    "            X_normalized[y == class_, 1],  # Select the y-coordinate for points of the current class\n",
    "            c=COLORS[\"class\"][class_dict_rev[class_]],  # Set color based on class\n",
    "            alpha=0.7,  # Make the points semi-transparent\n",
    "        )\n",
    "    \n",
    "    # If `annot` is True, annotate the points with class labels or images\n",
    "    if annot:\n",
    "        for index, image_coord in enumerate(X_normalized):\n",
    "            # Calculate the distance to the nearest previously plotted point\n",
    "            closest_distance = np.linalg.norm(neighbors - image_coord, axis=1).min()\n",
    "            \n",
    "            # If the distance is greater than the specified threshold, annotate the point\n",
    "            if closest_distance > min_distance:\n",
    "                neighbors = np.r_[neighbors, [image_coord]]  # Add this point to the list of plotted neighbors\n",
    "                \n",
    "                if images is None:\n",
    "                    # Annotate with class label if no images are provided\n",
    "                    ax.text(\n",
    "                        image_coord[0],  # x-coordinate\n",
    "                        image_coord[1],  # y-coordinate\n",
    "                        class_dict_rev[y[index]],  # Class label\n",
    "                        color=COLORS[\"class\"][class_dict_rev[y[index]]],  # Set text color based on class\n",
    "                        alpha=0.7,  # Make the text semi-transparent\n",
    "                        **FONT_KW[\"plot_text_small\"]  # Use small font for the text\n",
    "                    )\n",
    "                else:\n",
    "                    # If images are provided, add the image as annotation instead of text\n",
    "                    image = images[index].reshape(28, 28)  # Reshape the image to 28x28 pixels\n",
    "                    imagebox = AnnotationBbox(OffsetImage(image, cmap=\"binary\"), image_coord)  # Create the image annotation\n",
    "                    ax.add_artist(imagebox)  # Add the image to the plot\n",
    "    \n",
    "    # Set background color of the figure and axis\n",
    "    fig.patch.set_facecolor(COLORS[\"fig_bg\"])\n",
    "    ax.set_facecolor(COLORS[\"fig_bg\"])\n",
    "    \n",
    "    # Remove axis ticks and labels for a cleaner look\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    # Add a legend to the plot with the class names\n",
    "    ax.legend(\n",
    "        [class_short2full[class_dict_rev[label]] for label in np.unique(y)],  # Get full class names for the legend\n",
    "        prop={\"family\": \"serif\", \"size\": 8},  # Set font properties for the legend\n",
    "        facecolor=COLORS[\"fig_bg\"]  # Set the background color of the legend\n",
    "    )\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.555555Z",
     "iopub.status.busy": "2023-09-27T16:10:04.555187Z",
     "iopub.status.idle": "2023-09-27T16:10:04.567428Z",
     "shell.execute_reply": "2023-09-27T16:10:04.566307Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.555523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(img_list, class_label, ratio=1.0, max_images=None):\n",
    "    dataset = []  # List to store the processed images and their labels\n",
    "    count = 0  # Counter for the number of processed images\n",
    "    num_images = int(ratio * len(img_list))  # Number of images to process based on the ratio\n",
    "\n",
    "    # Loop through the image filenames in img_list\n",
    "    for img in img_list:\n",
    "        # If max_images is set, stop when the counter reaches it\n",
    "        if max_images is not None and count >= max_images:\n",
    "            break\n",
    "\n",
    "        # Skip images based on the specified ratio (chance of inclusion)\n",
    "        if random.random() > ratio:\n",
    "            continue\n",
    "\n",
    "        # Build the full image path\n",
    "        image_path = os.path.join(DATA_PATH, img)\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Skip the image if it is not read properly (None)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Convert the image from BGR (OpenCV default) to RGB format\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Resize the image to the specified size (IMG_SIZE x IMG_SIZE)\n",
    "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Append the processed image and its class label to the dataset\n",
    "        dataset.append([np.array(image), class_label])\n",
    "        count += 1  # Increment the count\n",
    "\n",
    "        # Stop if the desired number of images (num_images) has been processed\n",
    "        if count == num_images:\n",
    "            break\n",
    "\n",
    "    # Return the created dataset\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.570080Z",
     "iopub.status.busy": "2023-09-27T16:10:04.569329Z",
     "iopub.status.idle": "2023-09-27T16:10:04.591304Z",
     "shell.execute_reply": "2023-09-27T16:10:04.590298Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.570048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the class labels and calculate the number of classes\n",
    "CLASSES = [\"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"N\"]\n",
    "NUM_CLASSES = len(CLASSES)  # Total number of classes\n",
    "\n",
    "# Create a dictionary to map each class to a unique integer\n",
    "class_dict = {class_ : i for i, class_ in enumerate(CLASSES)}\n",
    "# Create a reverse dictionary to map each integer back to the class label\n",
    "class_dict_rev = {v: k for k, v in class_dict.items()}\n",
    "\n",
    "# Filter the data to keep only the rows where the \"class\" column matches one of the defined classes\n",
    "data = data.loc[data[\"class\"].isin(CLASSES)]\n",
    "\n",
    "# Create a dictionary where each key is a class and the value is a list of filenames belonging to that class\n",
    "dict_img_list = {\n",
    "    class_: data.loc[data[\"class\"] == class_][\"filename\"].values\n",
    "    for class_ in CLASSES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:04.595036Z",
     "iopub.status.busy": "2023-09-27T16:10:04.594496Z",
     "iopub.status.idle": "2023-09-27T16:10:05.146345Z",
     "shell.execute_reply": "2023-09-27T16:10:05.142254Z",
     "shell.execute_reply.started": "2023-09-27T16:10:04.595007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 6), dpi=70, gridspec_kw={\"wspace\": 0.5})\n",
    "\n",
    "# Set background color for the entire figure\n",
    "fig.patch.set_facecolor(COLORS[\"fig_bg\"])\n",
    "\n",
    "# Calculate the class distribution in the original data\n",
    "value_counts = data[\"class\"].value_counts().rename(\"num\").to_frame()\n",
    "value_counts[\"percent\"] = value_counts / value_counts.sum()  # Calculate percentage for each class\n",
    "value_counts.reindex(index=CLASSES)  # Reorder based on predefined class list\n",
    "\n",
    "# Create horizontal bar plot for the original class distribution\n",
    "b1 = ax1.barh(value_counts.index, value_counts[\"percent\"])\n",
    "\n",
    "# Customize y-ticks and labels\n",
    "ax1.set_yticks(value_counts.index, [class_short2full[i] for i in value_counts.index], **FONT_KW[\"plot_label_small\"], color=COLORS[\"plot_text\"])\n",
    "ax1.tick_params(axis=\"y\", length=0)\n",
    "ax1.set_title(\"Original\", loc=\"left\", **FONT_KW[\"subplot_title\"], color=COLORS[\"plot_text\"])  # Title for the left plot\n",
    "\n",
    "# Annotate the bars with the count and percentage\n",
    "ax1.bar_label(b1, labels=[str(val) + f\"\\n({str(np.round(100*pcnt,1))}%)\" for val, pcnt in zip(value_counts[\"num\"], value_counts[\"percent\"])],\n",
    "              padding=5, color=COLORS[\"plot_text\"], **FONT_KW[\"plot_text\"])\n",
    "\n",
    "# Set background color for the left plot\n",
    "ax1.set_facecolor(COLORS[\"fig_bg\"])\n",
    "\n",
    "# Set the color for each class' bar and its label\n",
    "for i in range(NUM_CLASSES):\n",
    "    c = COLORS[\"class\"][value_counts.index[i]]\n",
    "    ax1.get_yticklabels()[i].set_color(c)  # Set label color\n",
    "    b1[i].set_color(c)  # Set bar color\n",
    "\n",
    "# Hide x-axis for the left plot\n",
    "ax1.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# Remove the top, right, and bottom spines for the left plot\n",
    "for spine in [\"bottom\", \"right\", \"top\"]:\n",
    "    ax1.spines[spine].set_visible(False)\n",
    "\n",
    "# Perform data augmentation for the minority class ('G') to balance class distribution\n",
    "NUM_AUGMENTATIONS = 5\n",
    "value_counts_aug = value_counts.copy()  # Copy the original class distribution\n",
    "value_counts_aug.loc[\"G\", \"num\"] *= NUM_AUGMENTATIONS  # Increase the count for the 'G' class\n",
    "value_counts_aug[\"percent\"] = value_counts_aug[\"num\"] / value_counts_aug[\"num\"].sum()  # Recalculate the percentage\n",
    "\n",
    "# Create horizontal bar plot for the augmented class distribution\n",
    "b2 = ax2.barh(value_counts_aug.index, value_counts_aug[\"percent\"])\n",
    "\n",
    "# Customize y-ticks and labels for the augmented plot\n",
    "ax2.set_yticks(value_counts_aug.index, [class_short2full[i] for i in value_counts_aug.index], **FONT_KW[\"plot_label_small\"], color=COLORS[\"plot_text\"])\n",
    "ax2.tick_params(axis=\"y\", length=0)\n",
    "ax2.set_title(\"With Minority Class Augmentations\", loc=\"left\", **FONT_KW[\"subplot_title\"], color=COLORS[\"plot_text\"])  # Title for the right plot\n",
    "\n",
    "# Annotate the bars with the count and percentage for the augmented plot\n",
    "ax2.bar_label(b2, labels=[str(val) + f\"\\n({str(np.round(100*pcnt,1))}%)\" for val, pcnt in zip(value_counts_aug[\"num\"], value_counts_aug[\"percent\"])],\n",
    "              padding=5, color=COLORS[\"plot_text\"], **FONT_KW[\"plot_text\"])\n",
    "\n",
    "# Set background color for the right plot\n",
    "ax2.set_facecolor(COLORS[\"fig_bg\"])\n",
    "\n",
    "# Set the color for each class' bar and its label in the augmented plot\n",
    "for i in range(NUM_CLASSES):\n",
    "    c = COLORS[\"class\"][value_counts_aug.index[i]]\n",
    "    ax2.get_yticklabels()[i].set_color(c)  # Set label color\n",
    "    b2[i].set_color(c)  # Set bar color\n",
    "\n",
    "# Hide x-axis for the right plot\n",
    "ax2.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# Remove the top, right, and bottom spines for the right plot\n",
    "for spine in [\"bottom\", \"right\", \"top\"]:\n",
    "    ax2.spines[spine].set_visible(False)\n",
    "\n",
    "# Add a title for the entire figure\n",
    "plt.figtext(0, 1.05, \"Class Distribution\", **FONT_KW[\"plot_title\"], color=COLORS[\"plot_text\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:12.372085Z",
     "iopub.status.busy": "2023-09-27T16:10:12.371647Z",
     "iopub.status.idle": "2023-09-27T16:10:35.642567Z",
     "shell.execute_reply": "2023-09-27T16:10:35.641516Z",
     "shell.execute_reply.started": "2023-09-27T16:10:12.372049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the dataset\n",
    "dataset = []\n",
    "\n",
    "# Define the maximum number of images per class (not used directly in this code but defined for potential future use)\n",
    "max_images_per_class = 1000\n",
    "\n",
    "print(\"START building dataset\")\n",
    "\n",
    "# Iterate over the classes to build the dataset\n",
    "for i, class_ in enumerate(CLASSES):\n",
    "    # Print the progress message showing the class being processed\n",
    "    print(f\"[{i+1}/{len(CLASSES)}] adding {class_short2full[class_]} to dataset ...\")\n",
    "    \n",
    "    # Retrieve the list of image filenames for the current class\n",
    "    img_list = dict_img_list[class_]\n",
    "    \n",
    "    # Get the numeric label associated with the current class\n",
    "    class_label = class_dict[class_]\n",
    "    \n",
    "    # Add the images for the current class to the dataset using the `create_dataset` function\n",
    "    # Here, the `ratio` is set to 0.5, meaning only 50% of the images from the list will be included in the dataset\n",
    "    dataset += create_dataset(img_list, class_label, ratio=0.5)\n",
    "\n",
    "# Shuffle the dataset to ensure randomness in the order of images\n",
    "random.shuffle(dataset)\n",
    "\n",
    "print(\"COMPLETE building dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.645047Z",
     "iopub.status.busy": "2023-09-27T16:10:35.644600Z",
     "iopub.status.idle": "2023-09-27T16:10:35.651780Z",
     "shell.execute_reply": "2023-09-27T16:10:35.650777Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.645013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.654222Z",
     "iopub.status.busy": "2023-09-27T16:10:35.653166Z",
     "iopub.status.idle": "2023-09-27T16:10:35.780399Z",
     "shell.execute_reply": "2023-09-27T16:10:35.779316Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.654187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "image_size = 224\n",
    "num_classes = 7\n",
    "\n",
    "# Create the input features (images) and labels (class labels) from the dataset\n",
    "# `train_x_concate` is a numpy array of images reshaped to the required dimensions (224x224x3)\n",
    "train_x_concate = np.array([i[0] for i in dataset]).reshape(-1, image_size, image_size, 3)\n",
    "\n",
    "# `train_y_concate` is a numpy array of class labels\n",
    "train_y_concate = np.array([i[1] for i in dataset])\n",
    "\n",
    "# Split the dataset into training and validation sets (80% for training, 20% for validation)\n",
    "# `train_test_split` randomly splits the data, with a fixed random seed for reproducibility\n",
    "x_train_concate, x_val_concate, y_train_concate, y_val_concate = train_test_split(\n",
    "    train_x_concate, train_y_concate, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print the number of images in the training and validation sets\n",
    "print(f\"Number of images - Train: {len(x_train_concate)}, Validation: {len(x_val_concate)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.784513Z",
     "iopub.status.busy": "2023-09-27T16:10:35.783290Z",
     "iopub.status.idle": "2023-09-27T16:10:35.790373Z",
     "shell.execute_reply": "2023-09-27T16:10:35.789237Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.784478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the class labels to categorical format for use with categorical cross-entropy loss\n",
    "# `to_categorical` will convert the labels to a one-hot encoded format\n",
    "\n",
    "y_train_concate = to_categorical(y_train_concate, num_classes=num_classes)\n",
    "y_val_concate = to_categorical(y_val_concate, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.793925Z",
     "iopub.status.busy": "2023-09-27T16:10:35.793617Z",
     "iopub.status.idle": "2023-09-27T16:10:35.803377Z",
     "shell.execute_reply": "2023-09-27T16:10:35.802330Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.793899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of train_x:\", x_train_concate.shape)\n",
    "print(\"Shape of train_x:\", y_train_concate.shape)\n",
    "print(\"Shape of train_x:\", x_val_concate.shape)\n",
    "print(\"Shape of train_x:\", y_val_concate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.805055Z",
     "iopub.status.busy": "2023-09-27T16:10:35.804647Z",
     "iopub.status.idle": "2023-09-27T16:10:35.814393Z",
     "shell.execute_reply": "2023-09-27T16:10:35.813329Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.805023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(len(x_train_concate))\n",
    "print(len(y_train_concate))\n",
    "print(len(x_val_concate))\n",
    "print(len(y_val_concate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.816397Z",
     "iopub.status.busy": "2023-09-27T16:10:35.815841Z",
     "iopub.status.idle": "2023-09-27T16:10:35.825348Z",
     "shell.execute_reply": "2023-09-27T16:10:35.824330Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.816257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels back to class labels by taking the index of the highest value in each row\n",
    "y_train_labels = np.argmax(y_train_concate, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the training set\n",
    "test_class_counts = np.bincount(y_train_labels)\n",
    "\n",
    "# Print the number of images for each class in the training set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.827748Z",
     "iopub.status.busy": "2023-09-27T16:10:35.826749Z",
     "iopub.status.idle": "2023-09-27T16:10:35.841608Z",
     "shell.execute_reply": "2023-09-27T16:10:35.840560Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.827708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels for the validation set\n",
    "y_val_labels = np.argmax(y_val_concate, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the validation set\n",
    "test_class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "# Print the number of images for each class in the validation set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:35.844095Z",
     "iopub.status.busy": "2023-09-27T16:10:35.843074Z",
     "iopub.status.idle": "2023-09-27T16:10:37.911256Z",
     "shell.execute_reply": "2023-09-27T16:10:37.910165Z",
     "shell.execute_reply.started": "2023-09-27T16:10:35.844050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the train, validation, and test datasets (from real dataset)\n",
    "x_train = np.load('/kaggle/input/tsne-7-class-train-test-val/x_train.npy')\n",
    "y_train = np.load('/kaggle/input/tsne-7-class-train-test-val/y_train.npy')\n",
    "x_val = np.load('/kaggle/input/tsne-7-class-train-test-val/x_val.npy')\n",
    "y_val = np.load('/kaggle/input/tsne-7-class-train-test-val/y_val.npy')\n",
    "x_test = np.load('/kaggle/input/tsne-7-class-train-test-val/x_test.npy')\n",
    "y_test = np.load('/kaggle/input/tsne-7-class-train-test-val/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:37.917864Z",
     "iopub.status.busy": "2023-09-27T16:10:37.917469Z",
     "iopub.status.idle": "2023-09-27T16:10:38.412566Z",
     "shell.execute_reply": "2023-09-27T16:10:38.411468Z",
     "shell.execute_reply.started": "2023-09-27T16:10:37.917829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Concatenate the existing training data with the new dataset's training data\n",
    "combined_train_x = np.concatenate((x_train_concate, x_train), axis=0)\n",
    "combined_train_y = np.concatenate((y_train_concate, y_train), axis=0)\n",
    "\n",
    "# Concatenate the existing training data with the new dataset's training data\n",
    "combined_val_x = np.concatenate((x_val_concate, x_val), axis=0)\n",
    "combined_val_y = np.concatenate((y_val_concate, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:38.415552Z",
     "iopub.status.busy": "2023-09-27T16:10:38.414039Z",
     "iopub.status.idle": "2023-09-27T16:10:38.422717Z",
     "shell.execute_reply": "2023-09-27T16:10:38.421542Z",
     "shell.execute_reply.started": "2023-09-27T16:10:38.415514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels\n",
    "y_val_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the test set\n",
    "test_class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "# Print the number of images for each class in the test set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:38.425991Z",
     "iopub.status.busy": "2023-09-27T16:10:38.425148Z",
     "iopub.status.idle": "2023-09-27T16:10:38.435301Z",
     "shell.execute_reply": "2023-09-27T16:10:38.434181Z",
     "shell.execute_reply.started": "2023-09-27T16:10:38.425955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels\n",
    "y_val_labels = np.argmax(combined_train_y, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the test set\n",
    "test_class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "# Print the number of images for each class in the test set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:38.437100Z",
     "iopub.status.busy": "2023-09-27T16:10:38.436625Z",
     "iopub.status.idle": "2023-09-27T16:10:38.448855Z",
     "shell.execute_reply": "2023-09-27T16:10:38.447677Z",
     "shell.execute_reply.started": "2023-09-27T16:10:38.437064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels\n",
    "y_val_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the test set\n",
    "test_class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "# Print the number of images for each class in the test set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:38.450749Z",
     "iopub.status.busy": "2023-09-27T16:10:38.450405Z",
     "iopub.status.idle": "2023-09-27T16:10:38.462984Z",
     "shell.execute_reply": "2023-09-27T16:10:38.461952Z",
     "shell.execute_reply.started": "2023-09-27T16:10:38.450718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert one-hot encoded labels to class labels\n",
    "y_val_labels = np.argmax(combined_val_y, axis=1)\n",
    "\n",
    "# Count the occurrences of each class in the test set\n",
    "test_class_counts = np.bincount(y_val_labels)\n",
    "\n",
    "# Print the number of images for each class in the test set\n",
    "for class_label, count in enumerate(test_class_counts):\n",
    "    print(f\"Class {class_label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T16:10:38.464961Z",
     "iopub.status.busy": "2023-09-27T16:10:38.464605Z",
     "iopub.status.idle": "2023-09-27T16:10:38.913862Z",
     "shell.execute_reply": "2023-09-27T16:10:38.912749Z",
     "shell.execute_reply.started": "2023-09-27T16:10:38.464927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the combined training data for future use\n",
    "np.save('/kaggle/working/combined_train_x.npy', combined_train_x)\n",
    "np.save('/kaggle/working/combined_train_y.npy', combined_train_y)\n",
    "\n",
    "np.save('/kaggle/working/combined_val_x.npy', combined_val_x)\n",
    "np.save('/kaggle/working/combined_val_y.npy', combined_val_y)\n",
    "\n",
    "np.save('/kaggle/working/x_test.npy', x_test)\n",
    "np.save('/kaggle/working/y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
